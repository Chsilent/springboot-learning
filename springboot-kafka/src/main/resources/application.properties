#=========================mysql config=======================
spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/walker_test?useUnicode=true&characterEncoding=utf-8&useSSL=true
spring.datasource.username=root
spring.datasource.password=walker

#=========================mybatis mappers config=======================
mybatis.config-locations=classpath:mybatis/mybatis-config.xml
mybatis.mapperLocations=classpath:mappers/*.xml

#=========================kafka=======================
#代理地址producer和consumer
spring.kafka.bootstrap-servers=127.0.0.1:9092

#=========================kafka producer=======================
#生产者发送消息等待确认0,-1,all
spring.kafka.producer.acks=all
#发送重试次数
spring.kafka.producer.retries=0
#批处理数据大小，当消息记录达到该大小时发送到broker
spring.kafka.producer.batch-size=16384
#消息缓存区大小，单位字节
spring.kafka.producer.buffer-memory=40960
#消息key-value编码
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=========================kafka consumer=======================
#消费者消费完消息自动提交偏移量
spring.kafka.consumer.enable-auto-commit=true
#自动提交周期
spring.kafka.consumer.auto-commit-interval=1000ms
#从分区的开头消费消息
spring.kafka.consumer.auto-offset-reset=earliest


#消费组 为了重新消费消息，换一组消费组
spring.kafka.consumer.group-id=walkerTest3
#每次拉取最大条数
spring.kafka.consumer.max-poll-records=100

#消息key-value解码
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#消费监听器容器并发数
spring.kafka.listener.concurrency=3

